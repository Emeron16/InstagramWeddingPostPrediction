{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49dde11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 13:13:27.228206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from tensorflow.keras.models import load_model\n",
    "from pyngrok import ngrok, conf\n",
    "import getpass\n",
    "import threading\n",
    "from flasgger import Swagger\n",
    "from flask_cors import CORS\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2e7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FLASK_DEBUG\"] = \"development\"\n",
    "\n",
    "app = Flask(__name__)\n",
    "swagger = Swagger(app)\n",
    "CORS(app)\n",
    "port = 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(code_path,'hashtag_classification_Model_98ACC.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_popularity_category2(new_df, model, caption_tokenizer, hashtag_tokenizer, scaler, structured_columns,\n",
    "                                caption_maxlen=50, hashtag_maxlen=3):\n",
    "    \"\"\"\n",
    "    Predicts the popularity_category for new data using the trained classification model that includes hashtag features.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_df (pd.DataFrame): New data with the following columns:\n",
    "         'caption', 'dimensionsHeight', 'dimensionsWidth',\n",
    "         'hashtags/0', 'hashtags/1', 'hashtags/2',\n",
    "         'productType', 'type', 'day_of_week', 'season', 'month_of_year'\n",
    "         (Do not include the target column 'popularity_category'.)\n",
    "    - model (tf.keras.Model): The trained Keras classification model.\n",
    "    - caption_tokenizer (Tokenizer): The fitted Keras Tokenizer used for caption text processing.\n",
    "    - hashtag_tokenizer (Tokenizer): The fitted Keras Tokenizer used for hashtag text processing.\n",
    "    - scaler (StandardScaler): The fitted StandardScaler for numeric features.\n",
    "    - structured_columns (list or pd.Index): Column names of the structured features as produced by pd.get_dummies during training.\n",
    "    - caption_maxlen (int): Maximum length for padded caption sequences (default is 50).\n",
    "    - hashtag_maxlen (int): Maximum length for padded hashtag sequences (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - predictions (list): A list of predicted popularity categories as strings ('Low', 'Medium', or 'High') for each row.\n",
    "    \"\"\"\n",
    "    # --- Process Structured Features ---\n",
    "    # Drop text-related columns (caption and hashtag columns) to create the structured branch.\n",
    "    structured_data = new_df.drop(['caption', 'hashtags/0', 'hashtags/1', 'hashtags/2'], axis=1)\n",
    "    \n",
    "    # One-hot encode the categorical columns.\n",
    "    structured_data = pd.get_dummies(\n",
    "        structured_data,\n",
    "        columns=['productType', 'type', 'day_of_week', 'season', 'month_of_year']\n",
    "    )\n",
    "    \n",
    "    # Reindex the DataFrame to ensure it has the same columns as used in training.\n",
    "    structured_data = structured_data.reindex(columns=structured_columns, fill_value=0)\n",
    "    \n",
    "    # Scale the numeric columns (assuming they are 'dimensionsHeight' and 'dimensionsWidth').\n",
    "    structured_data[['dimensionsHeight', 'dimensionsWidth']] = scaler.transform(\n",
    "        structured_data[['dimensionsHeight', 'dimensionsWidth']]\n",
    "    )\n",
    "    \n",
    "    # Convert to a float32 NumPy array.\n",
    "    X_structured = structured_data.values.astype('float32')\n",
    "    \n",
    "    # --- Process Caption Text Features ---\n",
    "    # Convert the 'caption' column to a list of strings.\n",
    "    captions = new_df['caption'].astype(str).tolist()\n",
    "    # Tokenize and pad the caption sequences.\n",
    "    caption_sequences = caption_tokenizer.texts_to_sequences(captions)\n",
    "    X_text = pad_sequences(caption_sequences, maxlen=caption_maxlen).astype('int32')\n",
    "    \n",
    "    # --- Process Hashtag Features ---\n",
    "    # Combine the hashtag columns into one string per sample.\n",
    "    hashtags_combined = new_df[['hashtags/0', 'hashtags/1', 'hashtags/2']].astype(str).agg(\" \".join, axis=1)\n",
    "    # Tokenize and pad the combined hashtag text.\n",
    "    hashtag_sequences = hashtag_tokenizer.texts_to_sequences(hashtags_combined)\n",
    "    X_hashtag = pad_sequences(hashtag_sequences, maxlen=hashtag_maxlen).astype('int32')\n",
    "    \n",
    "    # --- Make Predictions ---\n",
    "    # The model expects three inputs: structured features, caption text, and hashtag text.\n",
    "    probs = model.predict([X_structured, X_text, X_hashtag])\n",
    "    predicted_indices = np.argmax(probs, axis=1)\n",
    "    \n",
    "    # Map numeric predictions to human-readable categories.\n",
    "    answer = []\n",
    "    for score in predicted_indices:\n",
    "        if score == 0:\n",
    "            answer.append('Low')\n",
    "        elif score == 1:\n",
    "            answer.append('Medium')\n",
    "        elif score == 2:\n",
    "            answer.append('High')\n",
    "    \n",
    "    print(f'Scale: Low(0-100), Medium(101-600), High(601 or More)')\n",
    "    return answer\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage:\n",
    "# -----------------------------\n",
    "# new_data should be a DataFrame with the columns:\n",
    "# 'caption', 'dimensionsHeight', 'dimensionsWidth',\n",
    "# 'hashtags/0', 'hashtags/1', 'hashtags/2',\n",
    "# 'productType', 'type', 'day_of_week', 'season', 'month_of_year'\n",
    "new_data = pd.DataFrame({\n",
    "    'caption': [\"Amazing product, works great!\", \"Terrible product, not recommended.\"],\n",
    "    'dimensionsHeight': [1500, 200],\n",
    "    'dimensionsWidth': [1000, 120],\n",
    "    'hashtags/0': [\"Wedding\", \"bad\"],\n",
    "    'hashtags/1': [\"trendy\", \"worse\"],\n",
    "    'hashtags/2': [\"sale\", \"cheap\"],\n",
    "    'productType': [\"clips\", \"TypeB\"],\n",
    "    'type': [\"Video\", \"SubType2\"],\n",
    "    'day_of_week': [\"Monday\", \"Tuesday\"],\n",
    "    'season': [\"Summer\", \"Winter\"],\n",
    "    'month_of_year': [6, 12]\n",
    "})\n",
    "\n",
    "# Assuming that the variables 'hashtag_classification_model', 'caption_tokenizer', 'hashtag_tokenizer', \n",
    "# 'scaler', and 'structured_columns' are defined (from training), call the prediction function:\n",
    "predicted_categories = predict_popularity_category2(new_data, hashtag_classification_model,\n",
    "                                                   caption_tokenizer, hashtag_tokenizer,\n",
    "                                                   scaler, structured_columns)\n",
    "print(\"Predicted popularity categories:\", predicted_categories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
